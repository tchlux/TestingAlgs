\relax 
\pgfsyspdfmark {pgfid1}{4736286}{17717152}
\citation{grobelny2007fase,wang2009simulation,wang2013towards}
\citation{snavely2002framework,bailey2005performance,barker2009using,ye2010analyzing}
\citation{bailey2005performance}
\citation{beckman2008benchmarking,de2007identifying}
\citation{lofstead2010managing}
\@writefile{toc}{\contentsline {section}{\numberline {1}\uppercase {Introduction and related work}}{2}}
\newlabel{sec:introduction}{{1}{2}}
\citation{friedman1991multivariate}
\citation{stanford1993fast}
\citation{rudy2017pyearth}
\citation{hornik1989multilayer}
\citation{dahl2013improving}
\citation{moller1993scaled}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {2}\uppercase {Multivariate Models}}{3}}
\newlabel{sec:multivariate}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Regression}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}\ \ \hspace  {1.5pt}{Multivariate Adaptive Regression Splines}}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}\ \ \hspace  {1.5pt}{Multilayer Perceptron Regressor}}{3}}
\citation{basak2007support}
\citation{scikit-learn}
\citation{lee1980two}
\citation{sartipizadeh2016computing}
\citation{scipy}
\citation{barber1996qhull}
\citation{thacker2010algorithm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}\ \ \hspace  {1.5pt}{Support Vector Regressor}}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Interpolation}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}\ \ \hspace  {1.5pt}{Delaunay}}{4}}
\citation{thacker2010algorithm}
\citation{iozone}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces A description of the system parameters being considered in the IOzone tests. Record size must not be greater than file size and hence there are only six valid combinations of the two. In total there are $6 \times 9 \times 16 = 864$ unique system configurations.}}{5}}
\newlabel{tab:data_type}{{1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}\ \ \hspace  {1.5pt}{Linear Shepard}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\uppercase {Methodology}}{5}}
\newlabel{sec:methodology}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Dimensional Analysis}{5}}
\citation{amos2014algorithm}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Histograms of 100-bin reductions of the PMF of I/O throughput mean (top) and I/O throughput sample variance (bottom). In the mean plot, the first 1\% bin (truncated in plot) has a probability mass of .45. In the variance plot, the first 1\% bin has a probability mass of .58. It can be seen that the distributions of throughputs are primarily of lower magnitude with occasional extreme outliers.}}{6}}
\newlabel{fig:raw_throughput}{{1}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}\ \ \hspace  {1.5pt}{Multidimensional Analysis}}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\uppercase {Results}}{7}}
\newlabel{sec:results}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}I/O Throughput Mean}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}I/O Throughput Variance}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Increasing Dimension and Decreasing Training Data}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces These box plots show the prediction error of mean with increasing amounts of training data provided to the models. Notice that MARS is the only model whose average spread of performance decreases with more training data. Recall that the response values being predicted span three orders of magnitude and hence relative errors should certainly remain within that range. For SVR the top box whisker goes from around 100 to 50 from left to right and is truncated in order to maintain focus on more performant models.}}{8}}
\newlabel{fig:mean_tt_ratio}{{2}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces These box plots show the prediction error of mean with increasing dimension. The top box whisker for SVR transitions \{40, 80, 90\} for dimensions 2, 3, and 4 respectively. Notice that each model consistently experiences greater magnitude error with increasing dimension.}}{8}}
\newlabel{fig:mean_dim}{{3}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\uppercase {Discussion}}{9}}
\newlabel{sec:discussion}{{5}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Modeling the System}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Extending the Analysis}{9}}
\bibstyle{scsproc}
\bibdata{paper}
\bibcite{amos2014algorithm}{\citeauthoryear {Amos, Easterling, Watson, Thacker, Castle, and Trosset}{Amos et\nobreakspace  {}al.}{2014}}
\bibcite{bailey2005performance}{\citeauthoryear {Bailey and Snavely}{Bailey and Snavely}{2005}}
\bibcite{barber1996qhull}{\citeauthoryear {Barber, Dobkin, and Huhdanpaa}{Barber et\nobreakspace  {}al.}{1996}}
\bibcite{barker2009using}{\citeauthoryear {Barker, Davis, Hoisie, Kerbyson, Lang, Pakin, and Sancho}{Barker et\nobreakspace  {}al.}{2009}}
\bibcite{basak2007support}{\citeauthoryear {Basak, Pal, and Patranabis}{Basak et\nobreakspace  {}al.}{2007}}
\bibcite{beckman2008benchmarking}{\citeauthoryear {Beckman, Iskra, Yoshii, Coghlan, and Nataraj}{Beckman et\nobreakspace  {}al.}{2008}}
\bibcite{dahl2013improving}{\citeauthoryear {Dahl, Sainath, and Hinton}{Dahl et\nobreakspace  {}al.}{2013}}
\bibcite{de2007identifying}{\citeauthoryear {De, Kothari, and Mann}{De et\nobreakspace  {}al.}{2007}}
\bibcite{friedman1991multivariate}{\citeauthoryear {Friedman}{Friedman}{1991}}
\bibcite{stanford1993fast}{\citeauthoryear {Friedman and Stanford\nobreakspace  {}University}{Friedman and Stanford\nobreakspace  {}University}{1993}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\uppercase {Conclusion}}{10}}
\newlabel{sec:conclusion}{{6}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Future Work}{10}}
\bibcite{grobelny2007fase}{\citeauthoryear {Grobelny, Bueno, Troxel, George, and Vetter}{Grobelny et\nobreakspace  {}al.}{2007}}
\bibcite{hornik1989multilayer}{\citeauthoryear {Hornik, Stinchcombe, and White}{Hornik et\nobreakspace  {}al.}{1989}}
\bibcite{scipy}{\citeauthoryear {Jones, Oliphant, Peterson, et\nobreakspace  {}al.}{Jones, Eric and Oliphant, Travis and Peterson, Pearu and others}{01 }}
\bibcite{lee1980two}{\citeauthoryear {Lee and Schachter}{Lee and Schachter}{1980}}
\bibcite{lofstead2010managing}{\citeauthoryear {Lofstead, Zheng, Liu, Klasky, Oldfield, Kordenbrock, Schwan, and Wolf}{Lofstead et\nobreakspace  {}al.}{2010}}
\bibcite{moller1993scaled}{\citeauthoryear {M{\o }ller}{M{\o }ller}{1993}}
\bibcite{iozone}{\citeauthoryear {Norcott}{Norcott}{2017}}
\bibcite{scikit-learn}{\citeauthoryear {Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay}{Pedregosa et\nobreakspace  {}al.}{2011}}
\bibcite{rudy2017pyearth}{\citeauthoryear {Rudy, Cherti, et\nobreakspace  {}al.}{Rudy et\nobreakspace  {}al.}{2017}}
\bibcite{sartipizadeh2016computing}{\citeauthoryear {Sartipizadeh and Vincent}{Sartipizadeh and Vincent}{2016}}
\bibcite{snavely2002framework}{\citeauthoryear {Snavely, Carrington, Wolter, Labarta, Badia, and Purkayastha}{Snavely et\nobreakspace  {}al.}{2002}}
\bibcite{thacker2010algorithm}{\citeauthoryear {Thacker, Zhang, Watson, Birch, Iyer, and Berry}{Thacker et\nobreakspace  {}al.}{2010}}
\bibcite{wang2009simulation}{\citeauthoryear {Wang, Butt, Pandey, and Gupta}{Wang et\nobreakspace  {}al.}{2009}}
\bibcite{wang2013towards}{\citeauthoryear {Wang, Khasymski, Krish, and Butt}{Wang et\nobreakspace  {}al.}{2013}}
\bibcite{ye2010analyzing}{\citeauthoryear {Ye, Jiang, Chen, Huang, and Wang}{Ye et\nobreakspace  {}al.}{2010}}
