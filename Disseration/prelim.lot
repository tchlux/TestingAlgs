\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {3.1}{\ignorespaces A description of the system parameters being considered in the IOzone tests. Record size must not be greater than file size and hence there are only six valid combinations of the two. In total there are $6 \times 9 \times 16 = 864$ unique system configurations.\relax }}{13}{table.caption.4}
\addvspace {10\p@ }
\contentsline {table}{\numberline {4.1}{\ignorespaces The optimal error tolerance bootstrapping parameters for each technique and each data set as well as the average absolute relative errors achieved by that tolerance. Notice that large relative error tolerances occasionally yield even lower evaluation errors, demonstrating the benefits of approximation over interpolation for noisy data sets. \vspace {-.5cm}\relax }}{34}{table.caption.15}
\addvspace {10\p@ }
\contentsline {table}{\numberline {5.1}{\ignorespaces A description of system parameters considered for IOzone. Record size must be $\leq $ file size during execution.\relax }}{41}{table.caption.19}
\contentsline {table}{\numberline {5.2}{\ignorespaces Percent of null hypothesis rejections rate by the KS-test when provided different selections of $p$-values. These accompany the percent of null hypothesis rejection results from Figure \ref {fig:ks_histogram_80_20}.\relax }}{45}{table.caption.22}
\contentsline {table}{\numberline {5.3}{\ignorespaces The null hypothesis rejection rates for various $p$-values with the KS-test. These results are strictly for the ``readers'' IOzone test type and show unweighted results as well as the results with weights tuned for minimum error (KS statistic) by 300 iterations of simulated annealing. Notice that the weights identified for the Delaunay model cause data dependent tuning, reducing performance. MaxBoxMesh performance is improved by a negligible amount. VoronoiMesh performance is notably improved.\relax }}{48}{table.caption.24}
\addvspace {10\p@ }
\contentsline {table}{\numberline {6.1}{\ignorespaces Numerical counterpart of the histogram data presented in Figure \ref {fig:throughput-prediction}. The columns display the percent of null hypothesis rejections by the KS-test when provided different selections of $p$-values for each algorithm. The algorithm with the lowest rejection rate at each $p$ is boldface, while the second lowest is italicized.\relax }}{65}{table.caption.37}
\contentsline {table}{\numberline {6.2}{\ignorespaces This average of Appendix Tables \ref {table:best-forest-fire}, \ref {table:best-parkinsons}, \ref {table:best-weather}, and \ref {table:best-credit-card} provides a gross summary of overall results. The columns display (weighted equally by data set, \textit {not} points) the average frequency with which any algorithm provided the lowest absolute error approximation, the average time to fit/prepare, and the average time required to approximate one point. The times have been rounded to one significant digit, as reasonably large fluctuations may be observed due to implementation hardware. Interpolants provide the lowest error approximation for nearly one third of all data, while regressors occupy the other two thirds. This result is obtained without any customized tuning or preprocessing to maximize the performance of any given algorithm. In practice, tuning and preprocessing may have large effects on approximation performance.\relax }}{66}{table.caption.38}
\addvspace {10\p@ }
\contentsline {table}{\numberline {7.1}{\ignorespaces This table depicts my expected timeline going forward. For details on when I achieved previous milestones, please contact me and I can provide the list. I refrained from including it here for brevity.\relax }}{73}{table.caption.43}
\addvspace {10\p@ }
\contentsline {table}{\numberline {A.1}{\ignorespaces This numerical data accompanies the visual provided in Figure \ref {fig:error-forest-fire}. The columns of absolute error percentiles correspond to the minimum, first quartile, median, third quartile, and maximum absolute errors respectively. The minimum of each column is boldface, while the second lowest value is italicized. All values are rounded to three significant digits.\relax }}{85}{table.caption.46}
\contentsline {table}{\numberline {A.2}{\ignorespaces The left above shows how often each algorithm had the lowest absolute error approximating forest fire data in Table \ref {table:error-forest-fire}. On the right columns are median fit time of 454 points, median time for one approximation, and median time approximating 50 points.\relax }}{85}{table.caption.47}
\contentsline {table}{\numberline {A.3}{\ignorespaces This numerical data accompanies the visual provided in Figure \ref {fig:error-parkinsons}. The columns of absolute error percentiles correspond to the minimum, first quartile, median, third quartile, and maximum absolute errors respectively. The minimum of each column is boldface, while the second lowest value is italicized. All values are rounded to three significant digits.\relax }}{86}{table.caption.48}
\contentsline {table}{\numberline {A.4}{\ignorespaces The left above shows how often each algorithm had the lowest absolute error approximating Parkinson's data in Table \ref {table:error-parkinsons}. On the right columns are median fit time of 5288 points, median time for one approximation, and median time approximating 587 points.\relax }}{86}{table.caption.49}
\contentsline {table}{\numberline {A.5}{\ignorespaces This numerical data accompanies the visual provided in Figure \ref {fig:error-weather}. The columns of absolute error percentiles correspond to the minimum, first quartile, median, third quartile, and maximum absolute errors respectively. The minimum value of each column is boldface, while the second lowest is italicized. All values are rounded to three significant digits.\relax }}{86}{table.caption.50}
\contentsline {table}{\numberline {A.6}{\ignorespaces Left table shows how often each algorithm had the lowest absolute error approximating Sydney rainfall data in Table \ref {table:error-weather}. On the right columns are median fit time of 2349 points, median time for one approximation, and median time approximating 260 points.\relax }}{87}{table.caption.51}
\contentsline {table}{\numberline {A.7}{\ignorespaces This numerical data accompanies the visual provided in Figure \ref {fig:error-credit-card}. The columns of absolute error percentiles correspond to the minimum, first quartile, median, third quartile, and maximum absolute errors respectively. The minimum value of each column is boldface, while the second lowest is italicized. All values are rounded to three significant digits.\relax }}{87}{table.caption.52}
\contentsline {table}{\numberline {A.8}{\ignorespaces The left above shows how often each algorithm had the lowest absolute error approximating credit card transaction data in Table \ref {table:error-credit-card}. On the right columns are median fit time of 5006 points, median time for one approximation, and median time approximating 556 points.\relax }}{87}{table.caption.53}
\contentsline {table}{\numberline {A.9}{\ignorespaces This numerical data accompanies the visual provided in Figure \ref {fig:error-throughput}. The columns of absolute error percentiles correspond to the minimum, first quartile, median, third quartile, and maximum KS statistics respectively between truth and guess for models predicting the distribution of I/O throughput that will be observed at previously unseen system configurations. The minimum value of each column is boldface, while the second lowest is italicized. All values are rounded to three significant digits.\relax }}{88}{table.caption.54}
\contentsline {table}{\numberline {A.10}{\ignorespaces The left above shows how often each algorithm had the lowest KS statistic on the I/O throughput distribution data in Table \ref {table:error-throughput}. On the right columns are median fit time of 2715 points, median time for one approximation, and median time approximating 301 points.\relax }}{88}{table.caption.55}
